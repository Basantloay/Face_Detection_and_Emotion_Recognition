{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_fill(test_array,h_max=255):\n",
    "    input_array = np.copy(test_array) \n",
    "    el = sp.ndimage.generate_binary_structure(2,2).astype(np.int)\n",
    "    inside_mask = sp.ndimage.binary_erosion(~np.isnan(input_array), structure=el)\n",
    "    output_array = np.copy(input_array)\n",
    "    output_array[inside_mask]=h_max\n",
    "    output_old_array = np.copy(input_array)\n",
    "    output_old_array.fill(0)   \n",
    "    el = sp.ndimage.generate_binary_structure(2,1).astype(np.int)\n",
    "    while not np.array_equal(output_old_array, output_array):\n",
    "        output_old_array = np.copy(output_array)\n",
    "        output_array = np.maximum(input_array,sp.ndimage.grey_erosion(output_array, size=(3,3), footprint=el))\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bwareaopen(img, min_size, connectivity=8):\n",
    "        \"\"\"Remove small objects from binary image (approximation of \n",
    "        bwareaopen in Matlab for 2D images).\n",
    "    \n",
    "        Args:\n",
    "            img: a binary image (dtype=uint8) to remove small objects from\n",
    "            min_size: minimum size (in pixels) for an object to remain in the image\n",
    "            connectivity: Pixel connectivity; either 4 (connected via edges) or 8 (connected via edges and corners).\n",
    "    \n",
    "        Returns:\n",
    "            the binary image with small objects removed\n",
    "        \"\"\"\n",
    "    \n",
    "        # Find all connected components (called here \"labels\")\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "            img, connectivity=connectivity)\n",
    "        \n",
    "        # check size of all connected components (area in pixels)\n",
    "        for i in range(num_labels):\n",
    "            label_size = stats[i, cv2.CC_STAT_AREA]\n",
    "            \n",
    "            # remove connected components smaller than min_size\n",
    "            if label_size < min_size:\n",
    "                img[labels == i] = 0\n",
    "                \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(img):\n",
    "    \n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    B = img[:,:,2]\n",
    "    \n",
    "    #inverse of the avg values of the RBG\n",
    "    mR = 1/(np.mean(np.mean(R)))\n",
    "    mG = 1/(np.mean(np.mean(G)))\n",
    "    mB = 1/(np.mean(np.mean(B)))\n",
    "    # smallest avg value\n",
    "    maxRGB = max(max(mR, mG), mB)\n",
    "    \n",
    "    #calculate the scaling factors\n",
    "    mR = mR/maxRGB\n",
    "    mG = mG/maxRGB\n",
    "    mB = mB/maxRGB\n",
    "\n",
    "    out = np.zeros(img.shape)\n",
    "    out = np.array(out, dtype=np.uint8)\n",
    "    #scale the values\n",
    "    out[:,:,0]=R*mR\n",
    "    out[:,:,1]=G*mG\n",
    "    out[:,:,2]=B*mB\n",
    "\n",
    "    #convert the RGB image to YCbCr\n",
    "    img_ycbcr =  cv2.cvtColor(out, cv2.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    #3. Extracting each component\n",
    "    Y= img_ycbcr[:,:,0]\n",
    "    Cb= img_ycbcr[:,:,1]\n",
    "    Cr= img_ycbcr[:,:,2]\n",
    "\n",
    "    #4. perform multi-level tresholding\n",
    "    r = []\n",
    "    c = []\n",
    "    for i in range(img_ycbcr.shape[0]):\n",
    "        for j in range(img_ycbcr.shape[1]):\n",
    "            if Cb[i,j]>=77 and Cb[i,j]<=127 and Cr[i,j]>=133 and Cr[i,j]<=193 :\n",
    "                r.append(i)\n",
    "                c.append(j)\n",
    "\n",
    "    numind=len(r)\n",
    "    bin=np.zeros((img.shape[0],img.shape[1]))\n",
    "    bin = np.array(bin, dtype=np.uint8)\n",
    "\n",
    "    for i in range(numind):\n",
    "        bin[r[i],c[i]]=1\n",
    "    bin = flood_fill(bin)\n",
    "    bin=bwareaopen(bin,9000)\n",
    "    R[bin == 0]=0\n",
    "    G[bin == 0]=0\n",
    "    B[bin == 0]=0\n",
    "\n",
    "    out[:,:,0] = R\n",
    "    out[:,:,1] = G\n",
    "    out[:,:,2] = B\n",
    "\n",
    "    out_gray = cv2.cvtColor(out, cv2.COLOR_BGR2GRAY)\n",
    "    out_gray[out_gray > 0] = 1\n",
    "    bounding_boxes = find_contours(out_gray, 0.8)\n",
    "\n",
    "    comps,labels= cv2.connectedComponents(out_gray, connectivity=8)\n",
    "\n",
    "    arr = []\n",
    "    for k in range(1,comps):\n",
    "        xcoordinate, ycoordinate = np.where(labels==k)\n",
    "        #print(ycoordinate)\n",
    "        #print(xcoordinate)\n",
    "        max_x = -9999999999\n",
    "        min_x = 9999999999\n",
    "\n",
    "        max_y = -999999999\n",
    "        min_y = 99999999999\n",
    "        for j in range(xcoordinate.shape[0]):\n",
    "            ypoint = ycoordinate[j]\n",
    "            xpoint = xcoordinate[j]\n",
    "            if(xpoint > max_x):\n",
    "                max_x = xpoint\n",
    "            if(xpoint < min_x):\n",
    "                min_x = xpoint\n",
    "            if(ypoint > max_y):\n",
    "                max_y = ypoint\n",
    "            if(ypoint < min_y):\n",
    "                min_y = ypoint\n",
    "        \n",
    "        arr.append([min_x, min_y, max_y-min_y, max_x-min_x])\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFiles(PATH, imgs, labels, label) -> None:\n",
    "    files = os.listdir(PATH)\n",
    "    num_images = len(files)\n",
    "    idx = 0\n",
    "    for f in files:\n",
    "        if(idx >= 100):\n",
    "            break\n",
    "        idx += 1\n",
    "        img = io.imread(os.path.join(PATH, f), as_gray=True)\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "    print(f\"Done reading label {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Training dataset from directories and label it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading label 1\n",
      "Done reading label 2\n",
      "Done reading label 3\n",
      "Done reading label 4\n",
      "Done reading label 5\n",
      "Done reading label 6\n",
      "Done reading label 7\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "labels = []\n",
    "features = []\n",
    "HAPPY_PATH = './train/happy'\n",
    "SAD_PATH = './train/sad'\n",
    "ANGRY_PATH = './train/angry'\n",
    "DISGUSTED_PATH = './train/disgusted'\n",
    "FEARFUL_PATH = './train/fearful'\n",
    "NEUTRAL_PATH = './train/neutral'\n",
    "SURPRISED_PATH = './train/surprised'\n",
    "readFiles(HAPPY_PATH,       imgs, labels, label=1)\n",
    "readFiles(SAD_PATH,         imgs, labels, label=2)\n",
    "readFiles(ANGRY_PATH,       imgs, labels, label=3)\n",
    "readFiles(DISGUSTED_PATH,   imgs, labels, label=4)\n",
    "readFiles(FEARFUL_PATH,     imgs, labels, label=5)\n",
    "readFiles(NEUTRAL_PATH,     imgs, labels, label=6)\n",
    "readFiles(SURPRISED_PATH,   imgs, labels, label=7)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_test = []\n",
    "labels_test = []\n",
    "features_test = []\n",
    "HAPPY_PATH = './test/happy'\n",
    "SAD_PATH = './test/sad'\n",
    "ANGRY_PATH = './test/angry'\n",
    "DISGUSTED_PATH = './test/disgusted'\n",
    "FEARFUL_PATH = './test/fearful'\n",
    "NEUTRAL_PATH = './test/neutral'\n",
    "SURPRISED_PATH = './test/surprised'\n",
    "# readFiles(HAPPY_PATH,       imgs_test, labels, label=1)\n",
    "# readFiles(SAD_PATH,         imgs_test, labels, label=2)\n",
    "# readFiles(ANGRY_PATH,       imgs_test, labels, label=3)\n",
    "# readFiles(DISGUSTED_PATH,   imgs_test, labels, label=4)\n",
    "# readFiles(FEARFUL_PATH,     imgs_test, labels, label=5)\n",
    "# readFiles(NEUTRAL_PATH,     imgs_test, labels, label=6)\n",
    "# readFiles(SURPRISED_PATH,   imgs_test, labels, label=7)\n",
    "# labels_test = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1:\n",
    " LPQ + PHOG + SVM(calssifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "cnt=  0\n",
    "for img in imgs:\n",
    "    lpq = apply_LPQ(img, 5)\n",
    "    lpq, _ = np.histogram(lpq, 256)\n",
    "    phog = PHOG_Algorithm(img, 8, 3)\n",
    "    feature: np.ndarray = np.concatenate((lpq, phog))\n",
    "    features.append(feature)\n",
    "    cnt += 1\n",
    "    if(cnt % 50 == 0):\n",
    "        print(cnt)\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5028571428571429\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=300)\n",
    "features_new = pca.fit_transform(features)\n",
    "pickle.dump(pca, open('model_1_PCA.sav', 'wb'))\n",
    "\n",
    "# Get the SVC classifier\n",
    "clf = svm.SVC()\n",
    "# Train the SVC with the training data (data points and labels)\n",
    "model = clf.fit(features_new, labels)\n",
    "pickle.dump(model, open(\"model1.sav\", 'wb'))\n",
    "# Predict the test samples\n",
    "pred = clf.predict(features_new)\n",
    "print(np.sum(labels == pred) / 700.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2:\n",
    "PHOG + SVM(calssifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "cnt=  0\n",
    "features_2 = []\n",
    "for img in imgs:\n",
    "    phog = PHOG_Algorithm(img, 8, 3)\n",
    "    features_2.append(phog)\n",
    "    cnt += 1\n",
    "    if(cnt % 50 == 0):\n",
    "        print(cnt)\n",
    "features_2 = np.array(features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=  0\n",
    "for img in imgs_test:\n",
    "    phog = PHOG_Algorithm(img, 8, 3)\n",
    "    features_test.append(phog)\n",
    "    cnt += 1\n",
    "    if(cnt % 50 == 0):\n",
    "        print(cnt)\n",
    "features_2 = np.array(features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when using only PHOG: 0.82\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=300)\n",
    "features_new = pca.fit_transform(features_2)\n",
    "pickle.dump(pca, open('model_2_PCA.sav', 'wb'))\n",
    "# Get the SVC classifier\n",
    "clf = svm.SVC()\n",
    "# Train the SVC with the training data (data points and labels)\n",
    "model = clf.fit(features_new, labels)\n",
    "pickle.dump(clf, open(\"model2.sav\", 'wb'))\n",
    "# pickle.dump(model, open(\"SVM.mod\", 'wb'))\n",
    "# Predict the test samples\n",
    "new = pca.transform(features_2[0].reshape((1, -1)))\n",
    "pred = clf.predict(features_new)\n",
    "acc = np.sum(labels == pred) / len(labels)\n",
    "print(f'Accuracy when using only PHOG: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3:\n",
    "LPQ + SVM(calssifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "features_3 = []\n",
    "cnt=  0\n",
    "for img in imgs:\n",
    "    lpq = apply_LPQ(img, 5)\n",
    "    lpq, _ = np.histogram(lpq, 256)\n",
    "    features_3.append(lpq)\n",
    "    cnt += 1\n",
    "    if(cnt % 50 == 0):\n",
    "        print(cnt)\n",
    "features_3 = np.array(features_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when using only LPQ: 0.5014285714285714\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=200)\n",
    "features_new = pca.fit_transform(features_3)\n",
    "pickle.dump(pca, open('model_3_PCA.sav', 'wb'))\n",
    "\n",
    "# Get the SVC classifier\n",
    "clf = svm.SVC()\n",
    "# Train the SVC with the training data (data points and labels)\n",
    "model = clf.fit(features_new, labels)\n",
    "pickle.dump(clf, open(\"model3.sav\", 'wb'))\n",
    "# pickle.dump(model, open(\"SVM.mod\", 'wb'))\n",
    "# Predict the test samples\n",
    "pred = clf.predict(features_new)\n",
    "acc = np.sum(labels == pred) / len(labels)\n",
    "print(f'Accuracy when using only LPQ: {acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4:\n",
    "LPQ + PHOG +LMNN(calssifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metric_learn import LMNN\n",
    "# pca = PCA(n_components=300)\n",
    "\n",
    "# features_new = pca.fit_transform(features)\n",
    "\n",
    "# lmnn = LMNN(k=5, learn_rate=1e-6)\n",
    "# lmnn.fit(features_new, labels)\n",
    "\n",
    "# pred = lmnn.(features_new)\n",
    "# acc = np.sum(labels == pred) / len(labels)\n",
    "# print(f'Accuracy when using LMNN + LPQ + PHOG: {acc}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cc131d2065e73f5f824eea86391850a23cf1e693b040521d5621046c8ca9bf0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
